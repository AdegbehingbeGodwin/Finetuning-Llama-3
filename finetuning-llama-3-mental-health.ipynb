{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10770916,"sourceType":"datasetVersion","datasetId":6681919}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:31:01.196947Z","iopub.execute_input":"2025-02-17T11:31:01.197205Z","iopub.status.idle":"2025-02-17T11:31:02.408291Z","shell.execute_reply.started":"2025-02-17T11:31:01.197169Z","shell.execute_reply":"2025-02-17T11:31:02.407579Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mentalhealth/counselchat.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install unsloth\n# Also get the latest nightly Unsloth!\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:31:02.409145Z","iopub.execute_input":"2025-02-17T11:31:02.409623Z","iopub.status.idle":"2025-02-17T11:35:01.202607Z","shell.execute_reply.started":"2025-02-17T11:31:02.409599Z","shell.execute_reply":"2025-02-17T11:35:01.201384Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 \ndtype = None \nload_in_4bit = True ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:35:01.203830Z","iopub.execute_input":"2025-02-17T11:35:01.204101Z","iopub.status.idle":"2025-02-17T11:35:39.877196Z","shell.execute_reply.started":"2025-02-17T11:35:01.204077Z","shell.execute_reply":"2025-02-17T11:35:39.876540Z"}},"outputs":[{"name":"stdout","text":"ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\nü¶• Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nlogin(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:35:39.878982Z","iopub.execute_input":"2025-02-17T11:35:39.879272Z","iopub.status.idle":"2025-02-17T11:35:40.110866Z","shell.execute_reply.started":"2025-02-17T11:35:39.879251Z","shell.execute_reply":"2025-02-17T11:35:40.110186Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import wandb\n\nwb_token = user_secrets.get_secret(\"wandb_api\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune-Llama-3.2-3B-Instruct on Counsel-Chat Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:37:18.906453Z","iopub.execute_input":"2025-02-17T11:37:18.906813Z","iopub.status.idle":"2025-02-17T11:37:31.692784Z","shell.execute_reply.started":"2025-02-17T11:37:18.906789Z","shell.execute_reply":"2025-02-17T11:37:31.692110Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgodwinadegbehingbe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250217_113725-be0lfxo5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset/runs/be0lfxo5' target=\"_blank\">rich-shape-1</a></strong> to <a href='https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset' target=\"_blank\">https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset/runs/be0lfxo5' target=\"_blank\">https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset/runs/be0lfxo5</a>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:37:31.693948Z","iopub.execute_input":"2025-02-17T11:37:31.694206Z","iopub.status.idle":"2025-02-17T11:37:46.366347Z","shell.execute_reply.started":"2025-02-17T11:37:31.694184Z","shell.execute_reply":"2025-02-17T11:37:46.365738Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.48.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc82e2a3ffd41219d6dbeefb4aa36c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b836553334814676b653588caaaa9637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dddb8bab0a374a78abb2e270708c8c19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8460c5a8494b1b967627ed764a123e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24209a43834e4f51b704e7f81645e75f"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  \n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0,  \n    bias=\"none\",  \n    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n    random_state=3407,\n    use_rslora=False,  \n    loftq_config=None,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:37:46.367261Z","iopub.execute_input":"2025-02-17T11:37:46.367459Z","iopub.status.idle":"2025-02-17T11:37:53.787687Z","shell.execute_reply.started":"2025-02-17T11:37:46.367440Z","shell.execute_reply":"2025-02-17T11:37:53.786955Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.2.12 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n\n# Define the formatting function for your dataset\ndef formatting_prompts_func(examples):\n    questions = examples[\"questionText\"]\n    answers = examples[\"answerText\"]\n    texts = []\n    for question, answer in zip(questions, answers):\n        # Use the train_prompt_style to format each example without a chain-of-thought section\n        text = train_prompt_style.format(question, answer) + EOS_TOKEN\n        texts.append(text)\n    return {\"text\": texts}\n\n# Load your CSV dataset into a Hugging Face Dataset\nfrom datasets import Dataset\ndataset = Dataset.from_csv(\"/kaggle/input/mentalhealth/counselchat.csv\", encoding=\"ISO-8859-1\")\n\n# Apply the formatting function to your dataset\ndataset = dataset.map(formatting_prompts_func, batched=True)\n\n# Preview the formatted text\nprint(dataset[\"text\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:37:53.794675Z","iopub.execute_input":"2025-02-17T11:37:53.794924Z","iopub.status.idle":"2025-02-17T11:38:00.253935Z","shell.execute_reply.started":"2025-02-17T11:37:53.794898Z","shell.execute_reply":"2025-02-17T11:38:00.253209Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d614a514f4254a1caa29db86c6b80faf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f5d4af66c84959a03ba897480f0bc7"}},"metadata":{}},{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context.\nWrite a response that appropriately completes the request in a supportive and empathetic manner.\n\n### Instruction:\nYou are a compassionate mental health counselor with expertise in emotional support and mental wellness. \nPlease respond to the following inquiry with empathy, understanding, and practical guidance.\n\n### Inquiry:\nI'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n   How can I change my feeling of being worthless to everyone?\n\n### Response:\nIf everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. ¬†Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. ¬†They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. ¬† Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.<|eot_id|>\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\nWrite a response that appropriately completes the request in a supportive and empathetic manner.\n\n### Instruction:\nYou are a compassionate mental health counselor with expertise in emotional support and mental wellness. \nPlease respond to the following inquiry with empathy, understanding, and practical guidance.\n\n### Inquiry:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:37:53.788849Z","iopub.execute_input":"2025-02-17T11:37:53.789086Z","iopub.status.idle":"2025-02-17T11:37:53.793833Z","shell.execute_reply.started":"2025-02-17T11:37:53.789056Z","shell.execute_reply":"2025-02-17T11:37:53.792951Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n        warmup_steps=5,\n        max_steps=60,\n        learning_rate=2e-4,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:38:00.254808Z","iopub.execute_input":"2025-02-17T11:38:00.255142Z","iopub.status.idle":"2025-02-17T11:38:06.658504Z","shell.execute_reply.started":"2025-02-17T11:38:00.255108Z","shell.execute_reply":"2025-02-17T11:38:06.657649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset (num_proc=2):   0%|          | 0/2129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2efd4f0ac7c342778568a2bafb014a5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/2129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7200f6b8a20643af895b06af6f9b07b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/2129 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92058e7499c04cb9b507122c49b31322"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:38:06.659352Z","iopub.execute_input":"2025-02-17T11:38:06.659637Z","iopub.status.idle":"2025-02-17T11:43:10.433288Z","shell.execute_reply.started":"2025-02-17T11:38:06.659613Z","shell.execute_reply":"2025-02-17T11:43:10.432398Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 2,129 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 24,313,856\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 04:52, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.543600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.066500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.028400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.993300</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.916000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.915100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:43:10.435072Z","iopub.execute_input":"2025-02-17T11:43:10.435318Z","iopub.status.idle":"2025-02-17T11:43:11.851755Z","shell.execute_reply.started":"2025-02-17T11:43:10.435295Z","shell.execute_reply":"2025-02-17T11:43:11.850959Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÅ‚ñÖ‚ñá‚ñÇ‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3574615023845376.0</td></tr><tr><td>train/epoch</td><td>0.22535</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.26949</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.9151</td></tr><tr><td>train_loss</td><td>2.07716</td></tr><tr><td>train_runtime</td><td>301.5842</td></tr><tr><td>train_samples_per_second</td><td>1.592</td></tr><tr><td>train_steps_per_second</td><td>0.199</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rich-shape-1</strong> at: <a href='https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset/runs/be0lfxo5' target=\"_blank\">https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset/runs/be0lfxo5</a><br> View project at: <a href='https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset' target=\"_blank\">https://wandb.ai/godwinadegbehingbe/Fine-tune-Llama-3.2-3B-Instruct%20on%20Counsel-Chat%20Dataset</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250217_113725-be0lfxo5/logs</code>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\nWrite a response that appropriately completes the request in a supportive and empathetic manner.\n\n### Instruction:\nYou are a compassionate mental health counselor with expertise in emotional support and mental wellness. \nPlease respond to the following inquiry with empathy, understanding, and practical guidance.\n\n### Inquiry:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:19:16.244270Z","iopub.execute_input":"2025-02-17T12:19:16.244675Z","iopub.status.idle":"2025-02-17T12:19:16.248586Z","shell.execute_reply.started":"2025-02-17T12:19:16.244643Z","shell.execute_reply":"2025-02-17T12:19:16.247542Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"question = \"I am depressed , what do i do?\"\n\n\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:19:16.806769Z","iopub.execute_input":"2025-02-17T12:19:16.807209Z","iopub.status.idle":"2025-02-17T12:19:24.768160Z","shell.execute_reply.started":"2025-02-17T12:19:16.807173Z","shell.execute_reply":"2025-02-17T12:19:24.767255Z"}},"outputs":[{"name":"stdout","text":"\nI am sorry to hear that you are depressed. ¬†There are several things you can do to help yourself, and I will list them below. ¬†Please talk to a mental health professional, such as a therapist or counselor, to discuss your feelings and develop a plan to help you get better. ¬†It is very important to seek help from a mental health professional if you are depressed. ¬†Depression can be a very serious illness that can cause you to become suicidal. ¬†If you are feeling suicidal, please call a suicide hotline, such as the National Suicide Prevention Lifeline at 1-800-273-TALK (8255).<|eot_id|>\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"question = \"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue, and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative, gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium. What is the most likely predisposing factor for this patient's condition?\"\n\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:19:33.601294Z","iopub.execute_input":"2025-02-17T12:19:33.601631Z","iopub.status.idle":"2025-02-17T12:19:42.232088Z","shell.execute_reply.started":"2025-02-17T12:19:33.601604Z","shell.execute_reply":"2025-02-17T12:19:42.231324Z"}},"outputs":[{"name":"stdout","text":"\nThe patient's symptoms of fever, chills, night sweats, and generalized fatigue are classic for endocarditis. The fact that the patient has a vegetation on the aortic valve suggests that the patient has a condition known as subacute bacterial endocarditis. The fact that the patient has a vegetation on the aortic valve is a predisposing factor for this condition. The most common predisposing factors for subacute bacterial endocarditis are a history of a heart defect, a history of intravenous drug use, and a history of a prosthetic heart valve. The fact that the patient is a 59-year-old man with a history of intravenous drug use is a predisposing factor for this patient's condition.<|eot_id|>\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"new_model_online = \"GodwinSage/Mental-Health\"\nnew_model_local = \"Mental-Health\"\nmodel.save_pretrained(new_model_local) # Local saving\ntokenizer.save_pretrained(new_model_local)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:21:45.361375Z","iopub.execute_input":"2025-02-17T12:21:45.361781Z","iopub.status.idle":"2025-02-17T12:21:46.024042Z","shell.execute_reply.started":"2025-02-17T12:21:45.361754Z","shell.execute_reply":"2025-02-17T12:21:46.023271Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('Mental-Health/tokenizer_config.json',\n 'Mental-Health/special_tokens_map.json',\n 'Mental-Health/tokenizer.json')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"model.push_to_hub(new_model_online) # Online saving\ntokenizer.push_to_hub(new_model_online) # Online saving","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:21:46.312489Z","iopub.execute_input":"2025-02-17T12:21:46.312763Z","iopub.status.idle":"2025-02-17T12:21:51.427346Z","shell.execute_reply.started":"2025-02-17T12:21:46.312741Z","shell.execute_reply":"2025-02-17T12:21:51.426143Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bae40f5b42dd4df5b77826c1dfacd097"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a3a49655ed43938549c8aa4aee6303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/97.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84ca56d4ba734f32af74396a8dbd841d"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/GodwinSage/Mental-Health\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f26969adba415ab43fff3f5caeed97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a8582de9e1f49d4b221d2e4f451fee9"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\",)\nmodel.push_to_hub_merged(new_model_online, tokenizer, save_method = \"merged_16bit\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:21:57.303044Z","iopub.execute_input":"2025-02-17T12:21:57.303380Z","iopub.status.idle":"2025-02-17T12:23:50.159592Z","shell.execute_reply.started":"2025-02-17T12:21:57.303353Z","shell.execute_reply":"2025-02-17T12:23:50.158639Z"}},"outputs":[{"name":"stderr","text":"Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\nWe shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\nTo force `safe_serialization`, set it to `None` instead.\nUnsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\nmodel which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\nUnsloth: Will remove a cached repo with size 2.4G\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 19.04 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 30.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving Mental-Health/pytorch_model-00001-of-00002.bin...\nUnsloth: Saving Mental-Health/pytorch_model-00002-of-00002.bin...\nDone.\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: You are pushing to hub in Kaggle environment.\nTo save memory, we shall move GodwinSage/Mental-Health to /tmp/Mental-Health\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 18.99 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:00<00:00, 32.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer...","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":" Done.\nUnsloth: Saving /tmp/Mental-Health/pytorch_model-00001-of-00002.bin...\nUnsloth: Saving /tmp/Mental-Health/pytorch_model-00002-of-00002.bin...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c7764478354b009a9b7110b981d1d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc9ec67d2d5a43479cf89f0386ebfd9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9db1f7f4578424c95fde03ad50f95a4"}},"metadata":{}},{"name":"stdout","text":"Done.\nSaved merged model to https://huggingface.co/GodwinSage/Mental-Health\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}